<p>With my financial background in stock market trading systems, the founder of my previous company decided to propose a new challenge for me, to lead the building of a system to manage his stock portfolio that could make smart and fast trade decisions based on technical analysis.</p>

<p>After 2 years, this project became a software product named Put.Call.Bot and the founder started to offer our trading services to his wealthy friends and family offices.</p>

<p>Put.Call.Bot is a software solution that evaluates quantitative analysis from real time Bovespa exchange market data, sending buy and sell signals to brokers according to the algorithmic strategy chosen by the trader. Our automated trading system is a very powerful web platform that allows our clients to work from any web browser or device.</p>

<p>On the web interface, the trader can configure several strategies and  watch the transactions that were made by the Algorithmic Trading System (ATS) that we have developed.</p>

<p><strong>Nowadays I am responsible for modernizing our .NET Framework ecosystem from a monolithic architecture to a Service Oriented Architecture, using AWS Lambda Function, DynamoDB, AWS RDS for SQL Server, AWS S3 Bucket, .NET 8, Entity Framework, Docker images and applying the .NET Microservices Architecture. I am coding on a VS Code Dev Container running Docker on a Ubuntu/Linux EC2 Instance and using GitHub for version control. I am also applying a micro front end design concept but it is still in the early days of development.</strong></p>

<p>These are some key contributions I have made to this platform ecosystem:</p>

<ul>
	<li style="list-style-type:disc">I designed and implemented all the system architecture:
	<ul>
		<li style="list-style-type:circle">Developed many server side applications, coding in C# and consuming .NET Framework libraries. I decided to use this development stack because our Quant logic layer needs a robust, performance driven solution and it must be easy to code and maintain, complying with our continuous integration and deployment constraint. Actually the complete platform project has 2.5K classes in 280K lines of code in 2K C# files managed by Subversion.</li>
		<li style="list-style-type:circle">Designed the relational database in SQLServer, queries and procedures. Nowadays we keep only users, profiles and strategies records into SQL Server. The quotes and tickers data besides the custody and order transactions were moved and now are stored in a NoSQL simple CSV file storage. Because of the lack of performance given by our relational database and the data volume to be stored and processed, I decided to use a file system model, using an object oriented model concept and a straightforward CSV architecture for the quotes tickers. Just the ticker database has around 200 GB and grows 40 MB per stock market day.</li>
		<li style="list-style-type:circle">Developed a multi-client server application that evaluates quantitative analysis from real time Bovespa exchange market data, sending buy and sell signals to brokers according to the algorithmic strategy chosen by the trader. Our automated trading system is a very powerful web platform that allows our clients to work from any web browser or device.</li>
		<li style="list-style-type:circle">Some strategies were developed in collaboration with 2 mathematician PHDs teachers from the Federal University of Santa Catarina</li>
		<li style="list-style-type:circle">Developed the Web Portal Front End, where the trader can configure several strategies and watch the transactions that were made by the robot ATS. The user interface uses HTML5 standard and the dynamic content is written in JavaScript language code using JQUERY, JSON and AJAX standards</li>
		<li style="list-style-type:circle">It is also possible to send manual orders and let the robot ATS manage them. The trader can work with virtual orders or set to route them to his broker. One or more broker accounts can be saved and used. I managed our platform integration with the IT teams from the largest Brazilian brokers, like BTG, Genial and XP Group using RESTFul API and other protocols like the Financial Information eXchange (FIX). Nowadays we are integrated to these brokers using a proprietary tailor-made solution which I’ve built directly on the electronic trading Metatrader platform coded using C++ language. Unfortunately, in 2019, the XP Broker compliance board decided to suspend our streaming services with their endpoints, interrupting our direct communication tunnel using the Financial Information eXchange FIX protocol. The reason was we represent individual investors and only large fund managers and asset control groups would be granted the FIX channel and their VPN access. It means without this workaround I hacked into the Metatrader platform, our project would be discontinued. So I am very proud to come up with an alternative solution in a couple of days researching.</li>
		<li style="list-style-type:circle">Developed the Backtest Module which allows the trader to create, debug, test, optimize, and execute trading robots in an exclusive environment totally independent from the production server. The user can request a development server to safely build and test their algo strategies. When the work is done, all these strategies can be published to production in the real world environment. I developed a procedure that consumes the AWS API to create an EC2 spot instance from an image prepared for this backtest environment, then from our web application, the user can seamlessly request a backtest server in an easy way, and our backtest environment is available on demand for the user. The backtest environment reproduces the real world condition because all ticks captured in production and used by the robot ATS are saved and exported to the backtest server in the same sequence order that happened.</li>
		<li style="list-style-type:circle">Developed using TradingView javascript libraries some interactive charts, like Candle charts in different timeframes, Strategy Return Performance against a benchmark index.</li>
		<li style="list-style-type:circle">Developed third party brokerage platform API integrations to some financial market solution providers like Cedro, Nelogica, MetaQuotes, using their TCP endpoints</li>
		<li style="list-style-type:circle">In the beginning of the project, back in 2014, I developed an integration to TD Ameritrade Broker firm streaming a HTTP long-lived connection to receive NYSE and NASDAQ trade signals. I could also send order requests and receive transaction status. It was not a REST API, and now it&rsquo;s completely obsolete.</li>
		<li style="list-style-type:circle">Developed the Messenger module which handles alert or information messages that can be sent to our users by Short Message Service or e-mail using AWS Simple Email Service.</li>
		<li style="list-style-type:circle">Developed the Monitoring module that checks the health condition of our services and maintenance tasks. One of the responsibilities of this module is to verify if a stock quote streaming or transaction broker channel is down and display an alert on the user screen and also sends me and to our stakeholders an email to allow us to promptly take action by our contingency plan.</li>
		<li style="list-style-type:circle">Developed a web server application that manages our AWS instances, following a schedule routine, this application starts and shutdowns our servers, in a way to reduce our hour consumption. This application also allows the creation of on demand or low cost spot servers. The server side consumes the AWS .NET API in order to request or monitor our cloud resources. I designed an API that allows our services located in our Virtual Private Cloud machines to request server resources. For instance, our users can create individual environment spaces for configuring and testing their strategies (Backtest server) and in the background a spot server is requested.</li>
		<li style="list-style-type:circle">Created a javascript framework library to help build dynamic and responsive web interfaces, including dialog windows, forms, dynamic and smart spreadsheets, reports and client-server communication consuming our REST API services.</li>
		<li style="list-style-type:circle">Worked in collaboration with the designers team from the firm we hired to do the digital marketing and our web design identity. We also created our public web pages.</li>
		<li style="list-style-type:circle">Our system is certified in Brazil by Bovespa Exchange compliance for routing client orders. I was responsible for writing and sending all documents requested by their compliance team.</li>
	</ul>
	</li>
	<li style="list-style-type:disc">I designed all the infrastructure in AWS cloud, including servers specifications and configurations:
	<ul>
		<li style="list-style-type:circle">Network interfaces (DNS, route definition, Virtual Private Cloud VPC, Elastic IPs, Route 53).</li>
		<li style="list-style-type:circle">For tradeoff reasons and redundancy, I also configured our DNS map in the IBM cloud.</li>
		<li style="list-style-type:circle">Security rules (Security Groups, Firewall rules, Key Pairs, IAM).</li>
		<li style="list-style-type:circle">VPN integration with third party Brokers.</li>
		<li style="list-style-type:circle">Region datacenter tradeoff analysis.</li>
		<li style="list-style-type:circle">Capacity, instance on-demand and spot instances creation on the fly by a web server application which I developed.</li>
		<li style="list-style-type:circle">Image (AMI backup) and storage definitions (Glacier for long term data archiving like some of our backup and log files), scheduled automated creation for fast backup recovery and mainly to provide to our users on demand server resources prepared for our backtest environment.</li>
		<li style="list-style-type:circle">Simple Email Service (AWS SES) integration with our platform to send registration and operational messages to our users, also to send system monitor messages to myself and our stakeholders in order to alert us about critical platform health conditions, allowing us to fast apply our contingency plan</li>
		<li style="list-style-type:circle">Implemented a VPN solution to solve an unknown compatibility issue that caused a 40% loss of packages and connectivity instability between our AWS VPC and the VPN of XP Broker, which is the biggest broker in Brazil and its services are used by all of our users. Unfortunately the AWS engineers were not giving a solution in reasonable time, so I had to research an alternative. I found a flexible SDN solution provided by Cohesive Networks. I created a Linux machine from an AMI with their solution, configured it in our VPC and set the two tunnels with the CIsco switcher solution in the XP Broker network endpoint. The package loss went to zero and our platform stopped losing trade signals. Like any broker or stock trade transaction environment, our trade platform needs a streaming channel with a very strict network throughput and failover process.</li>
		<li style="list-style-type:circle">Implemented and configured the Subversion (SVN) service in our server for our private version control system.</li>
		<li style="list-style-type:circle">Trying to be as cost effective as possible, designed our current Windows network to have one t3.micro server running 24/7 which is opened to internet traffic on a Demilitarized Zone DMZ concept. The basic idea is to concentrate public requests to this server acting like a hub to our private and protected services. There are more key servers in our network, two t3.medium servers requesting just in time quotes and data markets signal from the Bovespa Stock Exchange stream channel. I benchmarked this dual configuration and realized that it would be worthwhile to split it into two small servers rather than a large one EC2 instance. We have one more t3.medium server running as a hub dedicated to send and receive our trade signals from the other business logical servers.There are more four t3.medium servers dedicated to our real time Quant strategies and a c6i.large server to provide our API&rsquo;s services, process reports, handle the user online broker activities and much more. Finally there are a flexible amount of on demand and spot t3.medium servers that are responsible for validation, backtesting, simulating and evaluating our Quant strategies and trade scenarios. I projected a task control system that consumes AWS API to switch on and off these dedicated servers only in the demanded stock exchange operation time, reducing considerably the machine time consumption costs. This multi layered design architecture has been proven very flexible, scalable and well fitted in my very tight budget.</li>		<li style="list-style-type:circle">I set up, troubleshoot and maintain our networks and servers which are compounded by Windows Servers 2022, IIS Web Servers 10 and SQL Servers 2022.</li>
	</ul>
	</li>
</ul>

<p>One of the key factors from this system is to be very accurate in a way that the market behavior captured in online normal market basis day can be reproduced later in our backtest environment. Another very important challenge is to send and receive our trade signals as fast as possible, reducing the network latency and the processing speed of our decision making procedures.</p>

<p>Even though I've been building and delivering great solutions so far, after ten years from the beginning, this project is not getting traction and it is still not profitable enough. So, I need to deal with a lean budget and I have to keep our costs as low as possible. In spite of using costly Windows servers, I use the free Microsoft development stack, SQL Server Express Edition and Visual Studio Community. I also try to use as many free license products as I can, like the VisualSVN Subversion Server and TortoiseSVN Client. Also, this budget constraint makes me more responsible when deploying a solution. I need to optimize my reasoning on how to consume less bandwidth, cpu, memory and storage resources.</p>

<p>In the year of 2023 I started a project to use some Deep Learning techniques using the ML.NET Framework with the purpose of getting better results in our prediction models. For this project I started to use VS Code and Google Colab for my training using some libraries and models using Python, Pandas, Jupyter, Seaborn, Scikit-learn, Keras and TensorFlow. But it is still in my early days of knowledge so I am not proficient yet. However, it is something that I am really curious and currently interested in.</p>
